{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in scraping information here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"fuyu\"\n",
    "season_jap = \"冬\"\n",
    "season_url = \"https://ouchidehaiku.com/winter/contents/seasonwords\"\n",
    "number_of_pages = 368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape kigo page (excluding pronunciation)\n",
    "\n",
    "def scrape_page_kigo(url)  -> list:\n",
    "    response = requests.get(url)   # this gets the URL\n",
    "    source = response.text        # .text is an attribute, it gets the text\n",
    "    soup = BeautifulSoup(source, \"lxml\")\n",
    "    \n",
    "    text= soup.find('ol').find_all(\"li\")\n",
    "\n",
    "    kigo_list=[]\n",
    "    for element in text:\n",
    "        kigo_and_pronunciation = element.find(\"h3\").get_text()\n",
    "        kigo = re.sub(r\"\"\"（.*）\"\"\", \"\", kigo_and_pronunciation)   # you need to remove the full-width Japanese parenthesis\n",
    "\n",
    "        kigo_list.append(kigo)\n",
    "\n",
    "    return kigo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape kigo page (including pronunciation)\n",
    "\n",
    "def scrape_page_pronunciation(url)  -> list:\n",
    "    response = requests.get(url)   # this gets the URL\n",
    "    source = response.text        # .text is an attribute, it gets the text\n",
    "    soup = BeautifulSoup(source, \"lxml\")\n",
    "    \n",
    "    text= soup.find('ol').find_all(\"li\")\n",
    "\n",
    "    pronunciation_list = []\n",
    "    for element in text:\n",
    "        kigo_and_pronunciation = element.find(\"h3\").get_text()\n",
    "\n",
    "        pronunciation = re.sub(r\"\"\"）\"\"\", \"\", kigo_and_pronunciation)\n",
    "        pronunciation = re.sub(r\"\"\".*（\"\"\", \"\", pronunciation)\n",
    "        pronunciation_list.append(pronunciation)\n",
    "\n",
    "    return pronunciation_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['愛日', 'アイヌ山葵', '相嘗祭', '青木の実', '青頸', '青首大根', '石蓴', '青鮫', '青写真', '青摺']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_page_kigo(season_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['あいじつ',\n",
       " 'あいぬわさび',\n",
       " 'あいんべのまつり',\n",
       " 'あおきのみ',\n",
       " 'あおくび',\n",
       " 'あおくびだいこん',\n",
       " 'あおさ',\n",
       " 'あおざめ',\n",
       " 'あおじゃしん',\n",
       " 'あおずり']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_page_pronunciation(season_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# driver = webdriver.Chrome()  # no need for executable path any more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spring (haru): 427 pages\n",
    "\n",
    "Summer (natsu): 591 pages\n",
    "\n",
    "Autumn (aki): 474 pages\n",
    "\n",
    "Winter (fuyu): 368 pages\n",
    "\n",
    "New Year (shinnen): 229 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://ouchidehaiku.com/newyear/contents/seasonwords/page/3\")\n",
    "\n",
    "link = driver.find_element(By.CSS_SELECTOR, \"span.next\")  # click to get to next page\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 1\n",
    "\n",
    "# click on next page button and scrape page, return list of kigo and list of pronunciations\n",
    "\n",
    "def click_and_scrape_page(url, num_pages) -> list:\n",
    "\n",
    "    kigo_list = scrape_page_kigo(url)                       # starting list for kigo\n",
    "    pronunciation_list = scrape_page_pronunciation(url)     # starting list for pronunciation\n",
    "\n",
    "    driver = webdriver.Chrome() \n",
    "    driver.get(url)\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        if i > 0:\n",
    "            link = driver.find_element(By.CLASS_NAME, \"next\")  # click to get to next page\n",
    "            link.click()\n",
    "            current_url = driver.current_url\n",
    "\n",
    "            response = requests.get(current_url)   # this gets the URL\n",
    "            source = response.text        # .text is an attribute, it gets the text\n",
    "            soup = BeautifulSoup(source, \"lxml\")\n",
    "            \n",
    "            text= soup.find('ol').find_all(\"li\")\n",
    "\n",
    "            for element in text:\n",
    "                kigo_and_pronunciation = element.find(\"h3\").get_text()\n",
    "                kigo = re.sub(r\"\"\"（.*）\"\"\", \"\", kigo_and_pronunciation)   # you need to remove the full-width Japanese parenthesis\n",
    "\n",
    "                kigo_list.append(kigo)\n",
    "\n",
    "                pronunciation = re.sub(r\"\"\"）\"\"\", \"\", kigo_and_pronunciation)\n",
    "                pronunciation = re.sub(r\"\"\".*（\"\"\", \"\", pronunciation)\n",
    "                pronunciation_list.append(pronunciation)  \n",
    "            \n",
    "                i = i-1\n",
    "\n",
    "    return kigo_list, pronunciation_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION 2 (for Winter and New_Year)\n",
    "\n",
    "# click on next page button and scrape page, return list of kigo and list of pronunciations\n",
    "\n",
    "def click_and_scrape_page2(url, num_pages) -> list:\n",
    "\n",
    "    kigo_list = scrape_page_kigo(url)                       # starting list for kigo\n",
    "    pronunciation_list = scrape_page_pronunciation(url)     # starting list for pronunciation\n",
    "\n",
    "    driver = webdriver.Chrome() \n",
    "    driver.get(url)\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        if i > 0:\n",
    "            link = driver.find_element(By.CSS_SELECTOR, \"span.next\")  # click to get to next page\n",
    "            link.click()\n",
    "            current_url = driver.current_url\n",
    "\n",
    "            response = requests.get(current_url)   # this gets the URL\n",
    "            source = response.text        # .text is an attribute, it gets the text\n",
    "            soup = BeautifulSoup(source, \"lxml\")\n",
    "            \n",
    "            text= soup.find('ol').find_all(\"li\")\n",
    "\n",
    "            for element in text:\n",
    "                kigo_and_pronunciation = element.find(\"h3\").get_text()\n",
    "                kigo = re.sub(r\"\"\"（.*）\"\"\", \"\", kigo_and_pronunciation)   # you need to remove the full-width Japanese parenthesis\n",
    "\n",
    "                kigo_list.append(kigo)\n",
    "\n",
    "                pronunciation = re.sub(r\"\"\"）\"\"\", \"\", kigo_and_pronunciation)\n",
    "                pronunciation = re.sub(r\"\"\".*（\"\"\", \"\", pronunciation)\n",
    "                pronunciation_list.append(pronunciation)  \n",
    "            \n",
    "                i = i-1\n",
    "\n",
    "    return kigo_list, pronunciation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuyu_scraping = click_and_scrape_page2(season_url, number_of_pages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "\n",
    "df = pd.DataFrame({\"kigo\": fuyu_scraping[0],\n",
    "                   \"pronunciation\": fuyu_scraping[1],\n",
    "                  \"season\": season_jap})\n",
    "\n",
    "df.to_csv(\"./\" + season + \"_kigo_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
